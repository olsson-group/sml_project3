{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64448466-5928-43c2-b827-51aee8bcf618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import python packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as geom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93628509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  os.chdir(f\"/content/sml_project3\")\n",
    "\n",
    "\n",
    "# import project files\n",
    "from sml_project3 import data\n",
    "from sml_project3 import mlops\n",
    "from sml_project3 import util\n",
    "from sml_project3 import model\n",
    "from sml_project3 import painn\n",
    "from sml_project3 import torsion\n",
    "\n",
    "from oracle import util as outil\n",
    "\n",
    "# reload\n",
    "import importlib\n",
    "importlib.reload(painn)\n",
    "importlib.reload(util)\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a9971-2b86-4da2-b307-1eac6f584b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MODEL: Basedistribution\n",
    "\n",
    "class BaseDistribution:\n",
    "    def __init__(self, ...):\n",
    "        # TODO: Implement the base distribution for your model. \n",
    "        # HINT: The std of the coordinates is 0.1277\n",
    "        ...\n",
    "    \n",
    "    def sample(self, ...):\n",
    "        # TODO: Implement a sampling function for the basebasedistribtion for your model.\n",
    "        \n",
    "        # HINT: This function must return a tensor of dimension [n_atoms, 3]\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c318a5-2ab2-4c3b-96a8-e258200c0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: BASELINE MODEL\n",
    "\n",
    "class BaselineModel:\n",
    "    def __init__(self, ...):\n",
    "        # TODO: Implement a baseline model for your experiments\n",
    "        ...\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # TODO: Implement the forward pass of the baseline model.\n",
    "        # HINT: This function must return a tensor of dimension [n_atoms, 3]\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822b571-cc55-427c-955a-84e7743b7d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MODEL: Equivariant readout \n",
    "\n",
    "class EquivariantReadout(torch.nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        # TODO: Implement the equivariant readout function for a the painn model \n",
    "        ...\n",
    "\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # TODO: Implement the readout function for the painn model which embeds all nodes\n",
    "        # with invariant and equivariant features\n",
    "    \n",
    "        # HINT: The input batch will have in and equivariant on it with shapes\n",
    "        # batch.equivariant_features.shape == (n_atoms, n_features, 3)\n",
    "        # batch.invariant_features.shape == (n_atoms, n_features) \n",
    "\n",
    "        # HINT: This function should return a tensor of shape [n_atoms, 3]\n",
    "        ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591dea2c-2bde-43be-b61c-e40d6dfdfbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: set up the training script\n",
    "\n",
    "readout = Readout(...)\n",
    "basedistribution = BaseDistribution(...)\n",
    "score = painn.Painn(n_features=..., readout=readout)\n",
    "cfm = model.CFM(score, basedistribution)\n",
    "\n",
    "dataset = data.Pentene1Dataset()\n",
    "dataloader = geom.data.DataLoader(dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b4280-e6da-4774-95a9-69a592c1679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# TODO: train your Baseline model and compare it against your Painn model\n",
    "# NOTE: you can resume the training of some model using: cfm = mlops.load(\"results/model/model_latest.pkl\")\n",
    "\n",
    "timer = util.Timer()\n",
    "step = 0\n",
    "for epoch in range(1000):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        t = torch.rand(len(batch)).type_as(batch.pos)\n",
    "        loss = cfm.get_loss(t, batch)\n",
    "        cfm.training_step(loss)\n",
    "        step += 1\n",
    "\n",
    "        if (step + 1) % 1000 == 0:\n",
    "            # HINT mlops.save(object, path) will save the pickled object at path, and likewise object = mlops.load(path) will load back the pickled object. \n",
    "            # Use this if you want to save your model during training\n",
    "\n",
    "            mlops.save(cfm, f\"results/model/model_{step}.pkl\")\n",
    "            mlops.save(cfm, f\"results/model/model_latest.pkl\")\n",
    "\n",
    "        print(f\"Batch: {i+1}/{len(dataloader)}, loss: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    print(\n",
    "        f\"epoch: {epoch}, step: {step}, time passed: {timer}, loss: {epoch_loss:.4f}\",\n",
    "    )\n",
    "    cfm.on_epoch_end(epoch_loss)\n",
    "\n",
    "# HINT using my implementation of the equivariant Readout and a painn model with 8 hidden features I was able to get a loss of 0.037 in 10.000 steps running locally on my laptop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe1761-f14b-46ac-8cda-b0b638544c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLING:\n",
    "# TODO: Make samples from your model: \n",
    "cfm = mlops.load(\"results/cfm_model/model_999.pkl\")  # load a trained model \n",
    "cfm.eval()\n",
    "\n",
    "n_samples = 100  # nr samples to generate\n",
    "base_dataset = data.BaseDistributionDataset(n_samples, basedistribution)  # dataset of basedistribution samples, following the molecular graph of pentene\n",
    "base_loader = geom.loader.DataLoader(base_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "samples = cfm.sample(base_loader, n_steps=100)  # shape (n_steps, n_samples, n_atoms, 3)\n",
    "samples = samples.cpu().numpy()\n",
    "\n",
    "mlops.save(samples, 'results/samples.pkl')  # save samples\n",
    "\n",
    "# NOTE: you can visualize numpy trajectories by running utils.nglview_pentene(samples) as the last command in a cell, samples must have shape (n_steps, 15, 3)\n",
    "sample_index = 0  # index of the sample to visualize\n",
    "util.nglview_pentene(samples[:, sample_index, :, :])  # NOTE: molecule might not display correctly if you use Colab so you might want to use local jupyter for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f702aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = mlops.load('results/samples.pkl')  # load generated samples\n",
    "sol_samples = torch.tensor(sol_data, device=device, dtype=torch.float32)\n",
    "\n",
    "samples_dataset = data.Pentene1Dataset(sol_samples[-1].cpu().numpy())  # dataset of model samples at t=1, following the molecular graph of pentene\n",
    "\n",
    "print(f\"Number of samples to evaluate: {len(samples_dataset)}\")\n",
    "samples_dataloader = geom.loader.DataLoader(samples_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate torsion angles\n",
    "\n",
    "torsion_evaluator = torsion.TorsionEvaluator()\n",
    "sampled_torsions = torsion_evaluator.evaluate(sol_data[-1])\n",
    "\n",
    "ref_torsions = ...  # TODO: compute torsions of reference dataset\n",
    "\n",
    "# TODO: visualize torsions and compare through some metric of your choice (e.g. KL divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate energies with oracle model\n",
    "\n",
    "oracle = outil.load_oracle(device=device)\n",
    "\n",
    "oracles = []\n",
    "for batch in samples_dataloader:\n",
    "    oracle_energies = oracle.get_energy(batch)\n",
    "    oracles.append(oracle_energies)\n",
    "\n",
    "# TODO: compute reference energies for the reference dataset\n",
    "# HINT: you can use the same oracle to compute reference energies\n",
    "\n",
    "refs = ...\n",
    "\n",
    "ref_energies = np.concatenate(refs, axis=0)\n",
    "oracle_energies = np.concatenate(oracles, axis=0)\n",
    "\n",
    "# TODO: visualize and compare the distributions of oracle_energies and ref_energies through some metric of your choice (e.g. KL divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f81346",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --version\n",
    "!pdflatex --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!eval \"$(/usr/libexec/path_helper)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
